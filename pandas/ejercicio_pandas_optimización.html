<!DOCTYPE html>
<html>
	<!-- http://hilite.me/ -->
	<head>
		<title>Data Viz. Big Data UAB</title>
		<link href="../styles/style.css" rel="stylesheet" type="text/css">
	</head>
	<body>

		<div class="container">
			<header>
					<p><a href="../index.html">Regresar al Inicio</a>
			</header>


			<h1>Ejercicio PANDAS con BigData</h1>
            <p>
                Uno de los principales problemas que podemos tener al trabajar con datos, es que el conjunto de información (dataset) es demasiado pesado. Cuando cargamos un dataset con la librería Pandas los datos se almacenan en memoria RAM. Este almacenamiento permite manipular los datos, pero es posible que la memoria requerida exceda la disponible.
            </p>
            <p>
                Además de este problema, existe el factor "tiempo". Cargar en memoria y procesar un dataset muy grande puede suponer largos tiempos de espera. Por lo tanto, es necesario encontrar soluciones. Para ello, lo más común es usar los parámetros de PANDAS <i>nrows</i>, <i>chunksize</i> o <i>sample</i>. Puedes encontrar información sobre cada uno de estos parámetros
                en la documentación oficial de PANDAS. Concretamente, en la sección dedicada a <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" target="_blank">DataFrame.read_csv(<i>params</i>)</a>.
            </p>
            <h3>Propuesta de ejercicios</h3>
            <p>En este <a href="https://drive.google.com/file/d/1463_ZJHS0E25lqFX9CaTE9ejUp_9TX9R/view?usp=drive_link" target="_blank">enlace</a> encontrarás un dataset de +4gb con todos los datos de Twitch en español del mes de febrero. Las capturas de datos se han realizado con el script de la clase anterior, ejecutado cada 15 minutos en un servidor. De ese dataset debes ser capaz de:</p>
            <ol>
                <li>Aislar del Dataset a Ibai Llanos</li>
                <li>...</li>
            </ol>
            
			<footer>
			<hr>	
			<p>Adrià Padila</p>
			</footer>
		</div>
	</body>



</html>